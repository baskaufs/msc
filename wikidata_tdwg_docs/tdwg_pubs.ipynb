{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import requests\n",
    "from time import sleep\n",
    "\n",
    "# Configuration\n",
    "accept_media_type = 'application/json'\n",
    "endpoint = 'https://query.wikidata.org/sparql'\n",
    "user_agent_header = 'author_disambiguation/0.1 (mailto:steve.baskauf@vanderbilt.edu)'\n",
    "sparql_sleep = 0.1\n",
    "\n",
    "# Function definitions\n",
    "def extract_local_name(iri):\n",
    "    \"\"\"Extracts the local name part of an IRI, e.g. a Q ID from a Wikidata IRI. Input: string. Returns: string.\"\"\"\n",
    "    # pattern is http://www.wikidata.org/entity/Q6386232\n",
    "    pieces = iri.split('/')\n",
    "    last_piece = len(pieces)\n",
    "    return pieces[last_piece - 1]\n",
    "\n",
    "def generate_sparql_header_dictionary(accept_media_type,user_agent_header):\n",
    "    request_header_dictionary = {\n",
    "        'Accept' : accept_media_type,\n",
    "#        'Content-Type': 'application/sparql-query',\n",
    "        'Content-Type': 'application/x-www-form-urlencoded',\n",
    "        'User-Agent': user_agent_header\n",
    "    }\n",
    "    return request_header_dictionary\n",
    "\n",
    "# The following function requires the request header generated above\n",
    "sparql_request_header = generate_sparql_header_dictionary(accept_media_type, user_agent_header)\n",
    "\n",
    "# Sends a query to the query service endpoint. \n",
    "# NOTE: sparql_request_header and endpoint are global variables defined earlier in the script\n",
    "def send_sparql_query(query_string):\n",
    "    # You can delete the two print statements if the queries are short. However, for large/long queries,\n",
    "    # it's good to let the user know what's going on.\n",
    "    #print('querying SPARQL endpoint to acquire item metadata')\n",
    "    #response = requests.post(endpoint, data=query_string.encode('utf-8'), headers=sparql_request_header)\n",
    "    response = requests.post(endpoint, data=dict(query=query_string), headers=sparql_request_header)\n",
    "    #print(response.text) # uncomment to view the raw response, e.g. if you are getting an error\n",
    "    data = response.json()\n",
    "\n",
    "    # Extract the values from the response JSON\n",
    "    results = data['results']['bindings']\n",
    "    \n",
    "    #print('done retrieving data')\n",
    "    # print(json.dumps(results, indent=2))\n",
    "    \n",
    "    sleep(sparql_sleep) # delay to avoid hitting the Query Service too fast\n",
    "    return results\n",
    "\n",
    "# ----------------------------\n",
    "# Begin main script\n",
    "# ----------------------------\n",
    "\n",
    "all_authors_frame = pd.read_csv('docs-authors.csv', na_filter=False, dtype = str)\n",
    "\n",
    "# Create a non-redundant list of author IRIs\n",
    "author_iris = list(set(all_authors_frame['contributor_iri']))\n",
    "author_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists to hold unique values\n",
    "ids = []\n",
    "names = []\n",
    "orcids = []\n",
    "viafs = []\n",
    "qids = []\n",
    "other_ids = []\n",
    "affiliation_qids = []\n",
    "\n",
    "# Extract information for each author\n",
    "for author_iri in author_iris:\n",
    "\n",
    "    # Find the first row that matches that author\n",
    "    for index, author in all_authors_frame.iterrows():\n",
    "        if author_iri == author['contributor_iri']:\n",
    "            ids.append(author_iri)\n",
    "            names.append(author['contributor_literal'])\n",
    "            affiliation_qids.append(extract_local_name(author['affiliation_uri']))\n",
    "            none_of_the_above = True\n",
    "            if 'https://orcid.org/' in author_iri:\n",
    "                none_of_the_above = False\n",
    "                orcids.append(extract_local_name(author_iri))\n",
    "            else:\n",
    "                orcids.append('')\n",
    "            if 'http://viaf.org/viaf/' in author_iri:\n",
    "                none_of_the_above = False\n",
    "                viafs.append(extract_local_name(author_iri))\n",
    "            else:\n",
    "                viafs.append('')\n",
    "            if 'http://www.wikidata.org/entity/' in author_iri:\n",
    "                none_of_the_above = False\n",
    "                qids.append(extract_local_name(author_iri))\n",
    "            else:\n",
    "                qids.append('')\n",
    "            if none_of_the_above:\n",
    "                other_ids.append(author_iri)\n",
    "            else:\n",
    "                other_ids.append('')\n",
    "            break # stop checking for matches and go on to next author IRI\n",
    "\n",
    "out_frame = pd.DataFrame({'qid': qids, 'id': ids, 'name': names, 'affiliation': affiliation_qids, 'orcid': orcids, 'viaf': viafs, 'other': other_ids})\n",
    "out_frame.to_csv('authors.csv', index = False)\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually added huh ID numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send SPARQL queries to match people to Q IDs by their various identifiers\n",
    "\n",
    "authors_frame = pd.read_csv('authors.csv', na_filter=False, dtype = str)\n",
    "\n",
    "for index, author in authors_frame.iterrows():\n",
    "    do_query = True\n",
    "    if author['orcid'] != '':\n",
    "        query_string = '''\n",
    "select distinct ?qid ?name\n",
    "where {\n",
    "  ?qid wdt:P496 \"''' + author['orcid'] + '''\".\n",
    "  ?qid rdfs:label ?name.\n",
    "  filter(lang(?name)=\"en\")\n",
    "  }\n",
    "'''\n",
    "    elif author['viaf'] != '':\n",
    "        query_string = '''\n",
    "select distinct ?qid ?name\n",
    "where {\n",
    "  ?qid wdt:P214 \"''' + author['viaf'] + '''\".\n",
    "  ?qid rdfs:label ?name.\n",
    "  filter(lang(?name)=\"en\")\n",
    "  }\n",
    "'''\n",
    "    elif author['huh'] != '':\n",
    "        query_string = '''\n",
    "select distinct ?qid ?name\n",
    "where {\n",
    "  ?qid wdt:P6264 \"''' + author['huh'] + '''\".\n",
    "  ?qid rdfs:label ?name.\n",
    "  filter(lang(?name)=\"en\")\n",
    "  }\n",
    "'''\n",
    "    else:\n",
    "        do_query = False\n",
    "    \n",
    "    if do_query:\n",
    "        #print(query_string)\n",
    "        results = send_sparql_query(query_string)\n",
    "        if len(results) > 0:\n",
    "            qid = extract_local_name(results[0]['qid']['value'])\n",
    "            print(qid)\n",
    "            author['qid'] = qid\n",
    "            print(results[0]['name']['value'])\n",
    "\n",
    "authors_frame.to_csv('authors_qids.csv', index = False)\n",
    "print('done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_frame = pd.read_csv('documents/documents.csv', na_filter=False, dtype = str)\n",
    "standards_frame = pd.read_csv('standards/standards.csv', na_filter=False, dtype = str)\n",
    "source_docs_frame = pd.read_csv('documents/docs.csv', na_filter=False, dtype = str)\n",
    "\n",
    "for index, document in out_frame.iterrows():\n",
    "    print(document['part_of_iri'])\n",
    "    document['partOf'] = standards_frame.loc[standards_frame.website == document['part_of_iri'], 'qid'].values[0]\n",
    "    \n",
    "out_frame.to_csv('documents/output.csv', index = False)\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match author items with documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_qid_frame = pd.read_csv('authors_qids.csv', na_filter=False, dtype = str)\n",
    "documents_frame = pd.read_csv('documents/documents.csv', na_filter=False, dtype = str)\n",
    "author_frame = pd.read_csv('documents/authors/authors.csv', na_filter=False, dtype = str)\n",
    "#author_frame = author_frame.head(5).copy()\n",
    "\n",
    "for index, author in author_frame.iterrows():\n",
    "    print(author['author_stated_as'])\n",
    "    # Look up Q ID\n",
    "    try:\n",
    "        author['author'] = author_qid_frame.loc[author_qid_frame.id == author['contributor_iri'], 'qid'].values[0]\n",
    "    except:\n",
    "        print(author)\n",
    "    # Look up Q ID\n",
    "    author['qid'] = documents_frame.loc[documents_frame.fullWork == author['author_ref1_referenceUrl'], 'qid'].values[0]\n",
    "    \n",
    "author_frame.to_csv('documents/authors/output.csv', index = False)\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
